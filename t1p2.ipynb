{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a2d5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import openpyx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c93b8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>FACPR</th>\n",
       "      <th>FACSHR</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>ewretd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>1985-12-31</td>\n",
       "      <td>7952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-31</td>\n",
       "      <td>7952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.3750</td>\n",
       "      <td>C</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.044071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-02-28</td>\n",
       "      <td>7952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.2500</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.060381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-03-31</td>\n",
       "      <td>7952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.4375</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.047192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>7952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>3793.0</td>\n",
       "      <td>0.016140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO        date  PERMCO  FACPR  FACSHR     PRC        RET  SHROUT  \\\n",
       "0   10000  1985-12-31    7952    NaN     NaN     NaN        NaN     NaN   \n",
       "1   10000  1986-01-31    7952    NaN     NaN -4.3750          C  3680.0   \n",
       "2   10000  1986-02-28    7952    NaN     NaN -3.2500  -0.257143  3680.0   \n",
       "3   10000  1986-03-31    7952    NaN     NaN -4.4375   0.365385  3680.0   \n",
       "4   10000  1986-04-30    7952    NaN     NaN -4.0000  -0.098592  3793.0   \n",
       "\n",
       "     ewretd  \n",
       "0  0.028021  \n",
       "1  0.044071  \n",
       "2  0.060381  \n",
       "3  0.047192  \n",
       "4  0.016140  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the excel file\n",
    "file_path = '/Users/conniechen/Desktop/cfar_data19702003.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d4c7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime for easier manipulation\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63c94ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by 'PERMNO' and 'date' to ensure correct chronological order\n",
    "df.sort_values(by=['PERMNO', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5834c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换RET列到数值，无法转换的设置为NaN\n",
    "df['RET'] = pd.to_numeric(df['RET'], errors='coerce')\n",
    "\n",
    "# 计算市场价值（ME）\n",
    "df['ME'] = df['PRC'] * df['SHROUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07bdf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来计算累计回报率，作为动量\n",
    "def calculate_momentum(returns_series, lookback_periods=6):\n",
    "    # 如果过去6个月没有足够的数据则返回NaN\n",
    "    if len(returns_series) < lookback_periods + 2:\n",
    "        return np.nan\n",
    "    \n",
    "    # 获取过去6个月的数据（不包括最近的2个月）\n",
    "    past_returns = returns_series[-(lookback_periods + 2):-2]\n",
    "    \n",
    "    # 计算累计回报率\n",
    "    momentum = (1 + past_returns).prod() - 1\n",
    "    return momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53f76574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate momentum\n",
    "\n",
    "def calculate_momentum(row):\n",
    "    # Assuming 'PRC' is the stock price column\n",
    "    # Calculate the momentum as described before\n",
    "    momentum = (row['PRC'] - row['PRC'].shift(7)) / row['PRC'].shift(7)\n",
    "    return momentum\n",
    "    \n",
    "# Add the 'Momentum' column to the DataFrame\n",
    "df['Momentum'] = df.groupby('PERMNO').apply(calculate_momentum).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b75a7408",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PRC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PRC'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 对每个PERMNO分组，然后应用动量计算函数\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERMNO\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRET\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_momentum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 删除含有NaN的行，以确保因变量和自变量行对齐\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOM\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/generic.py:428\u001b[0m, in \u001b[0;36mSeriesGroupBy.transform\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(klass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_transform_template)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1633\u001b[0m, in \u001b[0;36mGroupBy._transform\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m func \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func) \u001b[38;5;129;01mor\u001b[39;00m func\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m func \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m base\u001b[38;5;241m.\u001b[39mtransform_kernel_allowlist:\n\u001b[1;32m   1636\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid function name for transform(name)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/generic.py:459\u001b[0m, in \u001b[0;36mSeriesGroupBy._transform_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# this setattr is needed for test_transform_lambda_with_datetimetz\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m--> 459\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(klass(res, index\u001b[38;5;241m=\u001b[39mgroup\u001b[38;5;241m.\u001b[39mindex))\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# check for empty \"results\" to avoid concat ValueError\u001b[39;00m\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 对每个PERMNO分组，然后应用动量计算函数\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERMNO\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRET\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grouped_data\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalculate_momentum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 删除含有NaN的行，以确保因变量和自变量行对齐\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOM\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36mcalculate_momentum\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_momentum\u001b[39m(row):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Assuming 'PRC' is the stock price column\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Calculate the momentum as described before\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     momentum \u001b[38;5;241m=\u001b[39m (\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m7\u001b[39m)) \u001b[38;5;241m/\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m momentum\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PRC'"
     ]
    }
   ],
   "source": [
    "# 对每个PERMNO分组，然后应用动量计算函数\n",
    "grouped_data = df.groupby('PERMNO')['RET']\n",
    "df['MOM'] = grouped_data.transform(lambda x: calculate_momentum(x))\n",
    "\n",
    "# 删除含有NaN的行，以确保因变量和自变量行对齐\n",
    "df.dropna(subset=['RET', 'ME', 'MOM'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09118933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf747cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with the 'Momentum' column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4020421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate 'Size'\n",
    "\n",
    "def calculate_size(row):\n",
    "    # Assuming 'PRC' is the stock price column and 'SHROUT' is the number of shares outstanding\n",
    "    # Check if both 'PRC' and 'SHROUT' are positive and not NaN\n",
    "    if pd.notna(row['PRC']) and pd.notna(row['SHROUT']) and row['PRC'] > 0 and row['SHROUT'] > 0:\n",
    "        size = np.log(row['PRC'] * row['SHROUT'])\n",
    "    else:\n",
    "        size = np.nan  # Set to NaN if 'PRC' or 'SHROUT' is missing, zero, or negative\n",
    "    return size\n",
    "\n",
    "# Add the 'Size' column to the DataFrame\n",
    "df['Size'] = df.apply(calculate_size, axis=1)  # Calculate 'Size' for each row\n",
    "\n",
    "# Display the DataFrame with the 'Size' column\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c77eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cebc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate 'SHRCHG'\n",
    "#def calculate_shrchg(row):\n",
    "#    # Assuming 'SHROUT' is the number of shares outstanding\n",
    "#    # Calculate 'SHRCHG' as the difference between shares outstanding in the current row and the previous row\n",
    "#    shrchg = row['SHROUT'] - row['SHROUT'].shift(1)\n",
    "#    return shrchg\n",
    "\n",
    "# Add the 'SHRCHG' column to the DataFrame\n",
    "#df['SHRCHG'] = df.groupby('PERMNO').apply(calculate_shrchg).reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame with the 'SHRCHG' column\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate 'AdjustedShares' based on 'FactorToAdjustShares'\n",
    "def calculate_adjusted_shares(row):\n",
    "    # Assuming 'FactorToAdjustShares' is the factor to adjust shares outstanding\n",
    "    # Calculate 'AdjustedShares' as the product of 'FactorToAdjustShares' and 'SHROUT'\n",
    "    adjusted_shares = row['FACSHR'] * row['SHROUT']\n",
    "    return adjusted_shares\n",
    "\n",
    "# Add the 'AdjustedShares' column to the DataFrame\n",
    "df['AdjustedShares'] = df.apply(calculate_adjusted_shares, axis=1)\n",
    "\n",
    "# Display the DataFrame with the 'AdjustedShares' column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shrchg(row):\n",
    "    # Assuming 'AdjustedShares' is the number of adjusted shares outstanding\n",
    "    # Calculate 'SHRCHG' as the difference between the natural logarithm of the adjusted shares at time t\n",
    "    # and the natural logarithm of the adjusted shares at time t-11\n",
    "    shrchg = np.log(row['AdjustedShares']) - np.log(row['AdjustedShares'].shift(11))\n",
    "    return shrchg\n",
    "\n",
    "# Add the 'SHRCHG' column to the DataFrame\n",
    "df['SHRCHG'] = df.groupby('PERMNO').apply(calculate_shrchg).reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame with the 'SHRCHG' column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6e525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To recreate Panel A: Simple Statistics, we will calculate the Mean, 25th Percentile, Median, 75th Percentile, and Standard Deviation\n",
    "# for the 'Size', 'Momentum', and 'SHRCHG' columns.\n",
    "# We will also handle missing values as they cannot be used in these calculations.\n",
    "\n",
    "# Dropping the rows where 'Size', 'Momentum', or 'SHRCHG' is NaN since we cannot calculate statistics on NaN values\n",
    "#df_stats = df.dropna()\n",
    "#print(df_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54960a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required statistics for Panel A\n",
    "\n",
    "\n",
    "# Dropping the rows where 'Size', 'Momentum', or 'SHRCHG' is NaN since we cannot calculate statistics on NaN values\n",
    "df_stats = df.dropna(subset=['ME', 'MOM', 'SHRCHG', 'RET'])\n",
    "\n",
    "# Calculate the required statistics for Panel A\n",
    "panel_a_stats = {\n",
    "    'Variable': ['ME', 'MOM', 'SHRCHG', 'RET'],\n",
    "    'Mean': [df_stats['ME'].mean(), df_stats['MOM'].mean(), df_stats['SHRCHG'].mean(), df_stats['RET'].mean()],\n",
    "    '25th Percentile': [df_stats['ME'].quantile(0.25), df_stats['MOM'].quantile(0.25), df_stats['SHRCHG'].quantile(0.25), df_stats['RET'].quantile(0.25)],\n",
    "    'Median': [df_stats['ME'].median(), df_stats['MOM'].median(), df_stats['SHRCHG'].median(), df_stats['RET'].median()],\n",
    "    '75th Percentile': [df_stats['ME'].quantile(0.75), df_stats['MOM'].quantile(0.75), df_stats['SHRCHG'].quantile(0.75), df_stats['RET'].quantile(0.75)],\n",
    "    'Standard Deviation': [df_stats['ME'].std(), df_stats['MOM'].std(), df_stats['SHRCHG'].std(), df_stats['RET'].std()]\n",
    "}\n",
    "\n",
    "\n",
    "# Convert this dictionary into a DataFrame\n",
    "panel_a_df = pd.DataFrame(panel_a_stats)\n",
    "\n",
    "# Display Panel A: Simple Statistics\n",
    "panel_a_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac822062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of non-NaN values in the 'Size', 'Momentum', and 'SHRCHG' columns\n",
    "non_nan_counts = df[['MOM', 'SHRCHG']].count()\n",
    "\n",
    "# Additionally, let's check for any non-NaN values to ensure there's data to calculate statistics on\n",
    "non_nan_counts, df[['MOM', 'SHRCHG']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aadf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since 'SHRCHG' has no non-NaN values, we'll exclude it from Panel A statistics\n",
    "# Let's calculate the Panel A statistics again, this time only for 'Size' and 'Momentum'\n",
    "\n",
    "# Calculate the required statistics for Panel A without 'SHRCHG'\n",
    "panel_a_stats = {\n",
    "    'Variable': ['Size', 'Momentum'],\n",
    "    'Mean': [df['Size'].mean(), df['Momentum'].mean()],\n",
    "    '25th Percentile': [df['Size'].quantile(0.25), df['Momentum'].quantile(0.25)],\n",
    "    'Median': [df['Size'].median(), df['Momentum'].median()],\n",
    "    '75th Percentile': [df['Size'].quantile(0.75), df['Momentum'].quantile(0.75)],\n",
    "    'Standard Deviation': [df['Size'].std(), df['Momentum'].std()]\n",
    "}\n",
    "\n",
    "# Convert this dictionary into a DataFrame\n",
    "panel_a_df = pd.DataFrame(panel_a_stats)\n",
    "\n",
    "# Display Panel A: Simple Statistics without 'SHRCHG'\n",
    "panel_a_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pairwise correlation of the specified columns, excluding NaN values\n",
    "correlation_matrix = df[['ME', 'MOM', 'SHRCHG', 'RET']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be130739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create lagged columns for the variables you're interested in.\n",
    "# Here, we're creating a 1-month lag for illustration. You'll adjust this according to your data.\n",
    "df['ME_lag1'] = df['ME'].shift(1)  # Lag by 1 period\n",
    "df['MOM_lag1'] = df['MOM'].shift(1)  # Lag by 1 period\n",
    "df['SHRCHG_lag1'] = df['SHRCHG'].shift(1)  # Lag by 1 period\n",
    "df['RET_lag1'] = df['RET'].shift(1)  # Lag by 1 period\n",
    "\n",
    "# You can create more lagged columns as needed for your analysis.\n",
    "\n",
    "# Drop the initial rows where any lagged values would be NaN due to the shift.\n",
    "df = df.dropna(subset=['ME_lag1', 'MOM_lag1', 'SHRCHG_lag1', 'RET_lag1'])\n",
    "\n",
    "# Calculate the non-contemporaneous correlation matrix between the current and lagged values.\n",
    "non_contemporaneous_correlation_matrix = df[['ME', 'ME_lag1', 'MOM', 'MOM_lag1', 'SHRCHG', 'SHRCHG_lag1', 'RET', 'RET_lag1']].corr()\n",
    "\n",
    "# Display the non-contemporaneous correlation matrix\n",
    "print(non_contemporaneous_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 3\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "# 进行Fama-MacBeth回归分析\n",
    "# 首先定义自变量和因变量\n",
    "y = df['RET']  # 因变量为回报率\n",
    "X = df[['ME', 'MOM']]  # 自变量为市场价值、动量\n",
    "X = sm.add_constant(X)  # 添加常数项\n",
    "\n",
    "# 进行回归分析\n",
    "model = OLS(y, X).fit()\n",
    "\n",
    "# 输出回归系数的结果\n",
    "print(model.summary())\n",
    "\n",
    "# 展示包含市场价值（ME）和动量（MOM）的数据框的前几行\n",
    "print(df[['PERMNO', 'PRC', 'SHROUT', 'ME', 'RET', 'MOM']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 4\n",
    "\n",
    "# Calculate rolling returns for different periods\n",
    "df['RET_1M'] = df.groupby('PERMNO')['RET'].rolling(window=21).sum().reset_index(level=0, drop=True)\n",
    "df['RET_1Q'] = df.groupby('PERMNO')['RET'].rolling(window=63).sum().reset_index(level=0, drop=True)\n",
    "df['RET_6M'] = df.groupby('PERMNO')['RET'].rolling(window=126).sum().reset_index(level=0, drop=True)\n",
    "df['RET_1Y'] = df.groupby('PERMNO')['RET'].rolling(window=252).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# Define a function to calculate cumulative return as momentum\n",
    "def calculate_momentum(returns_series, lookback_periods=6):\n",
    "    if len(returns_series) < lookback_periods + 2:\n",
    "        return np.nan\n",
    "    past_returns = returns_series[-(lookback_periods + 2):-2]\n",
    "    momentum = (1 + past_returns).prod() - 1\n",
    "    return momentum\n",
    "\n",
    "# Ensure there are no zero or negative numbers in the SHROUT column\n",
    "df = df[df['SHROUT'] > 0]\n",
    "\n",
    "# Calculate stock change amount (SHRCHG)\n",
    "df['Log_SHROUT'] = np.log(df['SHROUT'])\n",
    "df['SHRCHG'] = df['Log_SHROUT'].diff(-6) - df['Log_SHROUT'].diff(-17)\n",
    "\n",
    "# Remove rows with NaN\n",
    "df.dropna(subset=['RET_1M', 'RET_1Q', 'RET_6M', 'RET_1Y', 'ME', 'MOM', 'SHRCHG'], inplace=True)\n",
    "\n",
    "# Independent variables\n",
    "X = df[['ME', 'MOM', 'SHRCHG']]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "\n",
    "# Regression for 1-month return\n",
    "y_1M = df['RET_1M']\n",
    "model_1M = sm.OLS(y_1M, X).fit()\n",
    "print(\"Regression results for 1-month return:\")\n",
    "print(model_1M.summary())\n",
    "\n",
    "# Regression for 1-quarter return\n",
    "y_1Q = df['RET_1Q']\n",
    "model_1Q = sm.OLS(y_1Q, X).fit()\n",
    "print(\"\\nRegression results for 1-quarter return:\")\n",
    "print(model_1Q.summary())\n",
    "\n",
    "# Regression for 6-month return\n",
    "y_6M = df['RET_6M']\n",
    "model_6M = sm.OLS(y_6M, X).fit()\n",
    "print(\"\\nRegression results for 6-month return:\")\n",
    "print(model_6M.summary())\n",
    "\n",
    "# Regression for 1-year return\n",
    "y_1Y = df['RET_1Y']\n",
    "model_1Y = sm.OLS(y_1Y, X).fit()\n",
    "print(\"\\nRegression results for 1-year return:\")\n",
    "print(model_1Y.summary())\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"\\nFirst few rows of the dataframe:\")\n",
    "print(df[['PERMNO', 'PRC', 'SHROUT', 'ME', 'RET', 'MOM', 'SHRCHG']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb58bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0913b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708af35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5392f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

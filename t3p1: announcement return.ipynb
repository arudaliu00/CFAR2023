{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wrds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTnQuAomxEPl",
        "outputId": "cdfb9b09-950c-4c25-ebae-9bb0b223006e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wrds) (1.5.3)\n",
            "Collecting psycopg2-binary (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.11.3)\n",
            "Collecting sqlalchemy<2 (from wrds)\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->wrds) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "Installing collected packages: sqlalchemy, psycopg2-binary, wrds\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.21\n",
            "    Uninstalling SQLAlchemy-2.0.21:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.49 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed psycopg2-binary-2.9.9 sqlalchemy-1.4.49 wrds-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rwN_aiBMw2FP",
        "outputId": "827062bc-1997-4284-f9e3-35249a96a254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading library list...\n",
            "Done\n",
            "请输入查询的开始时间（格式：YYYY-MM-DD）：2000-01-01\n",
            "请输入查询的截止时间（格式：YYYY-MM-DD）：2002-01-01\n",
            "请输入公告前的天数：3\n",
            "请输入公告后的天数：1\n",
            "请选择排序方式：\n",
            "1: 根据六个月的收益率\n",
            "2: 根据Standardized Unexpected Earnings (SUE)\n",
            "3: 根据Abnormal Return Around Earnings Announcement\n",
            "4: 根据Revision in Analyst Forecasts\n",
            "5: 输出全部\n",
            "请输入您的选择 (1/2/3/4/5): 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 1/20015 [00:00<3:37:52,  1.53chunk/s, remaining_time=3:38:13.160342]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 2/20015 [00:01<3:43:20,  1.49chunk/s, remaining_time=3:42:43.248951]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 3/20015 [00:02<3:57:04,  1.41chunk/s, remaining_time=3:53:00.640333]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 4/20015 [00:02<4:00:32,  1.39chunk/s, remaining_time=3:56:10.439566]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 5/20015 [00:03<4:01:17,  1.38chunk/s, remaining_time=3:57:28.242807]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 6/20015 [00:04<4:05:39,  1.36chunk/s, remaining_time=4:00:13.994932]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 7/20015 [00:04<3:55:23,  1.42chunk/s, remaining_time=3:56:30.800900]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 8/20015 [00:05<4:02:08,  1.38chunk/s, remaining_time=3:59:02.055169]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 9/20015 [00:06<3:57:48,  1.40chunk/s, remaining_time=3:57:50.382940]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 10/20015 [00:07<3:48:02,  1.46chunk/s, remaining_time=3:54:38.809980]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 11/20015 [00:07<3:58:31,  1.40chunk/s, remaining_time=3:57:08.946315]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 12/20015 [00:08<4:09:10,  1.34chunk/s, remaining_time=4:00:12.650179]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 13/20015 [00:09<4:57:36,  1.12chunk/s, remaining_time=4:13:16.053975]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 14/20015 [00:11<5:26:12,  1.02chunk/s, remaining_time=4:23:09.839827]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   0%|          | 15/20015 [00:11<5:05:27,  1.09chunk/s, remaining_time=4:22:41.643410]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['permno', 'date', 'ret', 'gvkey', 'datadate', 'ni', 'mv', 'bv', 'cf',\n",
            "       'rdq', 'market_ret', 'abr', 'abr_1', 'abr_2', 'abr_3', 'abr_4', 'abr_5',\n",
            "       'abr_6', 'abr_7', 'abr_8', 'ticker', 'statpers', 'meanest', 'revision',\n",
            "       'six_month_return', 'return_1y_after', 'return_2y_after',\n",
            "       'return_3y_after', 'future_six_month_return', 'book_to_market',\n",
            "       'cash_flow_to_price', 'earnings_diff', 'F_it', 'sue',\n",
            "       'avg_revision_next_6_months', 'avg_revision_from_month_7'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 15/20015 [00:12<4:37:10,  1.20chunk/s, remaining_time=4:22:41.643410]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-41f1b2a74b44>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmonths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mfuture_return_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mcrsp_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture_return_column_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_return_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wrds\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import cupy as cp\n",
        "from datetime import timedelta\n",
        "\n",
        "# Define paths for temporary and final files\n",
        "temp_crsp_path = 'temp_crsp.csv'\n",
        "temp_compustat_path = 'temp_compustat.csv'\n",
        "temp_ibes_path = 'temp_ibes.csv'\n",
        "temp_linking_table_path = 'temp_linking_table.csv'\n",
        "final_data_path = 'final_merged_data.csv'\n",
        "temp_market_return_path = 'temp_market_return.csv'\n",
        "\n",
        "# Connect to WRDS database\n",
        "db = wrds.Connection(wrds_username='ziluyang', wrds_password='8KGyqRs6b9$jmsx')\n",
        "\n",
        "# Get start and end dates for the query from the user\n",
        "start_date = input(\"Please enter the start date for the query (format: YYYY-MM-DD): \")\n",
        "end_date = input(\"Please enter the end date for the query (format: YYYY-MM-DD): \")\n",
        "\n",
        "# User input for the number of days before and after the announcement for ABR calculation\n",
        "days_before = int(input(\"Enter the number of days before the announcement: \"))\n",
        "days_after = int(input(\"Enter the number of days after the announcement: \"))\n",
        "\n",
        "# User input for selection\n",
        "print(\"Please select the sorting method:\")\n",
        "print(\"1: Based on six-month return\")\n",
        "print(\"2: Based on Standardized Unexpected Earnings (SUE)\")\n",
        "print(\"3: Based on Abnormal Return Around Earnings Announcement\")\n",
        "print(\"4: Based on Revision in Analyst Forecasts\")\n",
        "print(\"5: Output all\")\n",
        "choice = input(\"Enter your choice (1/2/3/4/5): \")\n",
        "\n",
        "# Retrieve CRSP data\n",
        "query_crsp = f\"\"\"\n",
        "    SELECT a.permno, a.date, a.ret\n",
        "    FROM crsp.msf AS a\n",
        "    JOIN crsp.msenames AS b ON a.permno = b.permno\n",
        "    WHERE a.date BETWEEN '{start_date}' AND '{end_date}'\n",
        "    AND b.exchcd BETWEEN 1 AND 3\n",
        "\"\"\"\n",
        "data_crsp = db.raw_sql(query_crsp)\n",
        "data_crsp.to_csv(temp_crsp_path, index=False)\n",
        "\n",
        "# Retrieve Compustat data\n",
        "query_compustat = f\"\"\"\n",
        "    SELECT gvkey, datadate, ni, prcc_f * csho as mv, seq as bv, oancf as cf\n",
        "    FROM comp.funda\n",
        "    WHERE indfmt = 'INDL'\n",
        "    AND datafmt = 'STD'\n",
        "    AND popsrc = 'D'\n",
        "    AND consol = 'C'\n",
        "    AND datadate BETWEEN '{start_date}' AND '{end_date}'\n",
        "\"\"\"\n",
        "data_compustat = db.raw_sql(query_compustat)\n",
        "data_compustat.to_csv(temp_compustat_path, index=False)\n",
        "\n",
        "# Retrieve I/B/E/S data\n",
        "query_ibes = f\"\"\"\n",
        "    SELECT ticker, statpers, meanest\n",
        "    FROM ibes.statsum_epsus\n",
        "    WHERE statpers BETWEEN '{start_date}' AND '{end_date}'\n",
        "\"\"\"\n",
        "data_ibes = db.raw_sql(query_ibes)\n",
        "data_ibes['revision'] = data_ibes.groupby('ticker')['meanest'].diff()  # Calculate revisions\n",
        "data_ibes.to_csv(temp_ibes_path, index=False)\n",
        "\n",
        "# Retrieve linking table\n",
        "query_linking_table = \"\"\"\n",
        "    SELECT a.gvkey, b.lpermno as permno\n",
        "    FROM comp.names AS a\n",
        "    JOIN crsp.ccmxpf_lnkhist AS b ON a.gvkey = b.gvkey\n",
        "    WHERE b.linktype IN ('LC', 'LU')\n",
        "    AND b.linkprim IN ('P', 'C')\n",
        "\"\"\"\n",
        "linking_table = db.raw_sql(query_linking_table)\n",
        "linking_table.to_csv(temp_linking_table_path, index=False)\n",
        "\n",
        "# Query market return data\n",
        "query_market_return = f\"\"\"\n",
        "    SELECT date, ret\n",
        "    FROM crsp.msf\n",
        "    WHERE date BETWEEN '{start_date}' AND '{end_date}'\n",
        "\"\"\"\n",
        "data_market_return = db.raw_sql(query_market_return)\n",
        "data_market_return.to_csv(temp_market_return_path, index=False)\n",
        "\n",
        "# Query RDQ data\n",
        "query_rdq = f\"\"\"\n",
        "    SELECT gvkey, rdq\n",
        "    FROM comp.fundq\n",
        "    WHERE rdq BETWEEN '{start_date}' AND '{end_date}'\n",
        "\"\"\"\n",
        "data_rdq = db.raw_sql(query_rdq)\n",
        "data_rdq.to_csv('temp_rdq.csv', index=False)\n",
        "\n",
        "# Query market equal-weighted return data\n",
        "query_market_equal_weighted_return = f\"\"\"\n",
        "    SELECT date, ewretd as market_ret\n",
        "    FROM crsp.msi\n",
        "    WHERE date BETWEEN '{start_date}' AND '{end_date}'\n",
        "\"\"\"\n",
        "data_market_equal_weighted_return = db.raw_sql(query_market_equal_weighted_return)\n",
        "data_market_equal_weighted_return.to_csv('temp_market_equal_weighted_return.csv', index=False)\n",
        "\n",
        "# Initialize parameters\n",
        "chunk_size = 50  # Adjust chunk_size to fit available memory\n",
        "total_chunks = sum(1 for _ in pd.read_csv(temp_crsp_path, chunksize=chunk_size))\n",
        "first_chunk = True\n",
        "\n",
        "with tqdm(total=total_chunks, desc=\"Processing\", unit=\"chunk\") as pbar:\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Gradually read and merge data\n",
        "    for crsp_chunk in pd.read_csv(temp_crsp_path, chunksize=chunk_size):\n",
        "\n",
        "        crsp_chunk = pd.merge(crsp_chunk, pd.read_csv(temp_linking_table_path), how='inner', on='permno')\n",
        "        crsp_chunk = pd.merge(crsp_chunk, pd.read_csv(temp_compustat_path), how='inner', left_on='gvkey', right_on='gvkey')\n",
        "\n",
        "        # Merge RDQ into the current chunk\n",
        "        data_rdq = pd.read_csv('temp_rdq.csv')\n",
        "        data_rdq['gvkey'] = data_rdq['gvkey'].astype(int)\n",
        "        crsp_chunk = pd.merge(crsp_chunk, data_rdq, how='left', on='gvkey')\n",
        "\n",
        "        # Calculate ABR\n",
        "        data_market_equal_weighted_return = pd.read_csv('temp_market_equal_weighted_return.csv')\n",
        "        crsp_chunk = pd.merge(crsp_chunk, data_market_equal_weighted_return, how='left', left_on='date', right_on='date')\n",
        "        ret_gpu = cp.array(crsp_chunk['ret'].values)\n",
        "        market_ret_gpu = cp.array(crsp_chunk['market_ret'].values)\n",
        "        crsp_chunk['abr'] = cp.asnumpy(ret_gpu - market_ret_gpu)\n",
        "\n",
        "        # For each stock and each announcement date, calculate the average ABR\n",
        "        for gvkey, group in crsp_chunk.groupby('gvkey'):\n",
        "            announcement_dates = group['rdq'].dropna().unique()\n",
        "            for i, announcement_date in enumerate(announcement_dates, 1):\n",
        "                group['date'] = pd.to_datetime(group['date'])\n",
        "                announcement_date = pd.to_datetime(announcement_date)\n",
        "                mask = (group['date'] >= announcement_date - pd.Timedelta(days=days_before)) & (group['date'] <= announcement_date + pd.Timedelta(days=days_after))\n",
        "                abr_gpu = cp.array(group.loc[mask, 'abr'].values)\n",
        "                mean_abr = cp.asnumpy(abr_gpu.mean())\n",
        "                crsp_chunk.loc[group.index, f'abr_{i}'] = mean_abr\n",
        "\n",
        "        # Data transformation\n",
        "        crsp_chunk['permno'] = crsp_chunk['permno'].astype(str)\n",
        "        crsp_chunk = pd.merge(crsp_chunk, pd.read_csv(temp_ibes_path), how='left', left_on='permno', right_on='ticker')\n",
        "\n",
        "        # Calculate six-month return using GPU\n",
        "        six_month_return_gpu = cp.empty_like(ret_gpu)\n",
        "        window_size = 6\n",
        "        for i in range(len(ret_gpu)):\n",
        "            start = max(i - window_size + 1, 0)\n",
        "            six_month_return_gpu[i] = ret_gpu[start:i+1].sum()\n",
        "        crsp_chunk['six_month_return'] = cp.asnumpy(six_month_return_gpu)\n",
        "\n",
        "        # Calculate future one, two, three years and six months return using GPU\n",
        "        for i in range(1, 4):\n",
        "            future_return_column_name = f'return_{i}y_after'\n",
        "            months = i * 12\n",
        "            future_return_gpu = cp.empty_like(ret_gpu)\n",
        "            for j in range(len(ret_gpu)):\n",
        "                start = j + 1\n",
        "                end = start + months\n",
        "                future_return_gpu[j] = ret_gpu[start:end].sum()\n",
        "            crsp_chunk[future_return_column_name] = cp.asnumpy(future_return_gpu)\n",
        "\n",
        "        # Specially add a column for future six months\n",
        "        future_six_month_return_gpu = cp.empty_like(ret_gpu)\n",
        "        for i in range(len(ret_gpu)):\n",
        "            start = i + 1\n",
        "            end = start + 6\n",
        "            future_six_month_return_gpu[i] = ret_gpu[start:end].sum()\n",
        "        crsp_chunk['future_six_month_return'] = cp.asnumpy(future_six_month_return_gpu)\n",
        "\n",
        "        # Calculate Book-to-Market Ratio and Cash flow-to-price Ratio using GPU\n",
        "        bv_gpu = cp.array(crsp_chunk['bv'].values)\n",
        "        mv_gpu = cp.array(crsp_chunk['mv'].values)\n",
        "        cf_gpu = cp.array(crsp_chunk['cf'].values)\n",
        "\n",
        "        crsp_chunk['book_to_market'] = cp.asnumpy(bv_gpu / mv_gpu)\n",
        "        crsp_chunk['cash_flow_to_price'] = cp.asnumpy(cf_gpu / mv_gpu)\n",
        "\n",
        "        # Calculate SUE\n",
        "        # Calculate the difference in earnings per share for each quarter\n",
        "        crsp_chunk['earnings_diff'] = crsp_chunk['ni'] - crsp_chunk['ni'].shift(4)\n",
        "\n",
        "        # Calculate the standard deviation of the difference in earnings per share for the past eight quarters\n",
        "        crsp_chunk['F_it'] = crsp_chunk['earnings_diff'].rolling(window=8).std()\n",
        "\n",
        "        # Calculate SUE using the above model\n",
        "        crsp_chunk['sue'] = crsp_chunk['earnings_diff'] / crsp_chunk['F_it']\n",
        "\n",
        "        # Calculate the average revision for the next 6 months\n",
        "        crsp_chunk['avg_revision_next_6_months'] = crsp_chunk.groupby('permno')['revision'].rolling(window=6).mean().reset_index(level=0, drop=True).shift(-6)\n",
        "\n",
        "        # Calculate the average revision starting from month 7\n",
        "        crsp_chunk['avg_revision_from_month_7'] = crsp_chunk.groupby('permno')['revision'].expanding(min_periods=7).mean().reset_index(level=0, drop=True).shift(-7)\n",
        "\n",
        "        # Print columns of crsp_chunk here\n",
        "        print(crsp_chunk.columns)\n",
        "\n",
        "        # Append data chunk to final file\n",
        "        mode = 'a' if not first_chunk else 'w'\n",
        "        header = first_chunk\n",
        "        crsp_chunk.to_csv(final_data_path, mode=mode, header=header, index=False)\n",
        "        first_chunk = False\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Calculate and display remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        estimated_total_time = (elapsed_time / pbar.n) * pbar.total\n",
        "        remaining_time = estimated_total_time - elapsed_time\n",
        "        remaining_time_str = str(timedelta(seconds=remaining_time))\n",
        "        pbar.set_postfix(remaining_time=remaining_time_str)\n",
        "\n",
        "# Print header information of the final file\n",
        "print(pd.read_csv(final_data_path, nrows=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.read_csv(final_data_path, nrows=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxFnhZJq8MPr",
        "outputId": "54c0330d-c429-42bc-f502-f48553ee39ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    permno        date       ret  gvkey    datadate     ni    mv      bv  \\\n",
            "0  10001.0  2000-01-31 -0.044118  12994  2000-06-30  1.297  19.8  13.961   \n",
            "1  10001.0  2000-01-31 -0.044118  12994  2000-06-30  1.297  19.8  13.961   \n",
            "2  10001.0  2000-01-31 -0.044118  12994  2000-06-30  1.297  19.8  13.961   \n",
            "3  10001.0  2000-01-31 -0.044118  12994  2000-06-30  1.297  19.8  13.961   \n",
            "4  10001.0  2000-01-31 -0.044118  12994  2000-06-30  1.297  19.8  13.961   \n",
            "\n",
            "      cf         rdq  ...  statpers  meanest  revision  six_month_return  \\\n",
            "0  0.616  2000-02-15  ...       NaN      NaN       NaN         -0.044118   \n",
            "1  0.616  2000-05-18  ...       NaN      NaN       NaN         -0.088235   \n",
            "2  0.616  2000-09-28  ...       NaN      NaN       NaN         -0.132353   \n",
            "3  0.616  2000-11-14  ...       NaN      NaN       NaN         -0.176471   \n",
            "4  0.616  2001-02-14  ...       NaN      NaN       NaN         -0.220588   \n",
            "\n",
            "   return_1y_after  return_2y_after  return_3y_after  future_six_month_return  \\\n",
            "0        -0.529412        -1.058824        -1.588235                -0.264706   \n",
            "1        -0.529412        -1.058824        -1.588235                -0.264706   \n",
            "2        -0.529412        -1.058824        -1.588235                -0.264706   \n",
            "3        -0.529412        -1.058824        -1.588235                -0.264706   \n",
            "4        -0.529412        -1.058824        -1.588235                -0.264706   \n",
            "\n",
            "   book_to_market  cash_flow_to_price  \n",
            "0        0.705101            0.031111  \n",
            "1        0.705101            0.031111  \n",
            "2        0.705101            0.031111  \n",
            "3        0.705101            0.031111  \n",
            "4        0.705101            0.031111  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "file_path = 'final_merged_data.csv'\n",
        "final_data = pd.read_csv(file_path, error_bad_lines=False)\n",
        "final_data['date'] = pd.to_datetime(final_data['date'])\n",
        "\n",
        "# Ensure data is sorted by time and permno\n",
        "final_data.sort_values(by=['permno', 'date'], inplace=True)\n",
        "\n",
        "# Calculate future returns for each different time period\n",
        "time_periods = [6, 12, 24, 36]  # 6 months, 1 year, 2 years, 3 years\n",
        "for period in time_periods:\n",
        "    col_name = f'future_{period}_month_return'\n",
        "    final_data[col_name] = final_data.groupby('permno')['ret'].rolling(window=period).sum().shift(-period).reset_index(level=0, drop=True)\n",
        "\n",
        "# Filter data: Only keep rows with necessary return data\n",
        "final_data.dropna(subset=['six_month_return', 'book_to_market', 'cash_flow_to_price'] + [f'future_{period}_month_return' for period in time_periods], inplace=True)\n",
        "\n",
        "# Get unique months\n",
        "unique_dates = final_data['date'].unique()\n",
        "\n",
        "# Initialize result DataFrame\n",
        "result_data = pd.DataFrame()\n",
        "\n",
        "# Classify stocks based on selected method\n",
        "def classify_by_choice(monthly_data, choice):\n",
        "    if choice == \"1\":\n",
        "        return monthly_data.sort_values(by='six_month_return', ascending=False)\n",
        "    elif choice == \"2\":\n",
        "        return monthly_data.sort_values(by='sue', ascending=False)\n",
        "    elif choice == \"3\":\n",
        "        return monthly_data.sort_values(by='abr_1', ascending=False)  # Assuming using the most recent month's abnormal return\n",
        "    elif choice == \"4\":\n",
        "        return monthly_data.sort_values(by='revision', ascending=False)\n",
        "\n",
        "# Rank and create decile groups for each month\n",
        "for date in unique_dates:\n",
        "    # Get data for the current month\n",
        "    monthly_data = final_data[final_data['date'] == date].copy()\n",
        "\n",
        "    # Check if monthly_data is empty, if so, continue to the next iteration\n",
        "    if monthly_data.empty:\n",
        "        continue\n",
        "\n",
        "    # Rank stocks based on the selected method\n",
        "    if choice != \"5\":\n",
        "        monthly_data = classify_by_choice(monthly_data, choice)\n",
        "    else:\n",
        "        for ch in [\"1\", \"2\", \"3\", \"4\"]:\n",
        "            monthly_data = classify_by_choice(monthly_data, ch)\n",
        "\n",
        "    # Calculate the size of each decile\n",
        "    decile_size = len(monthly_data) // 10\n",
        "\n",
        "    # Assign a decile to each stock\n",
        "    monthly_data['decile'] = (monthly_data.index // decile_size) + 1\n",
        "    monthly_data.loc[monthly_data['decile'] > 10, 'decile'] = 10  # Handle potential size imbalance in the last decile\n",
        "\n",
        "    # Append monthly data to the result DataFrame\n",
        "    result_data = pd.concat([result_data, monthly_data], axis=0)\n",
        "\n",
        "# Repeat the process for each month\n",
        "for date in unique_dates:\n",
        "    # Get data for the current month\n",
        "    monthly_data = final_data[final_data['date'] == date].copy()\n",
        "\n",
        "    # Rank stocks based on six-month returns\n",
        "    monthly_data.sort_values(by='six_month_return', ascending=False, inplace=True)\n",
        "\n",
        "    # Calculate the size of each decile\n",
        "    decile_size = len(monthly_data) // 10\n",
        "\n",
        "    # Assign a decile to each stock\n",
        "    monthly_data['decile'] = (monthly_data.index // decile_size) + 1\n",
        "    monthly_data.loc[monthly_data['decile'] > 10, 'decile'] = 10  # Handle potential size imbalance in the last decile\n",
        "\n",
        "    # Append monthly data to the result DataFrame\n",
        "    result_data = pd.concat([result_data, monthly_data], axis=0)\n",
        "\n",
        "# Print Panel A and Panel B\n",
        "columns = ['\"1\\n(Low)\"'] + [str(i) for i in range(2, 10)] + ['\"10\\n(High)\"']\n",
        "print(\"Panel A: Returns\")\n",
        "for period in time_periods:\n",
        "    col_name = f'future_{period}_month_return'\n",
        "    print(f'Return {period} months after portfolio formation', end=\"\\t\")\n",
        "    average_returns = result_data.groupby('decile')[col_name].mean()\n",
        "    for col, ret in zip(columns, average_returns):\n",
        "        print(\"{:.3f}\".format(ret), end=\"\\t\")\n",
        "    print()\n",
        "\n",
        "print(\"\\nPanel B: Characteristics\")\n",
        "\n",
        "# Calculate and print Book-to-market ratio for each decile\n",
        "print(\"Book-to-market ratio\", end=\"\\t\")\n",
        "average_book_to_market = result_data.groupby('decile')['book_to_market'].mean()\n",
        "for col, ratio in zip(columns, average_book_to_market):\n",
        "    print(\"{:.3f}\".format(ratio), end=\"\\t\")\n",
        "print()\n",
        "\n",
        "# Calculate and print Cash flow-to-price ratio for each decile\n",
        "print(\"Cash flow-to-price ratio\", end=\"\\t\")\n",
        "average_cash_flow_to_price = result_data.groupby('decile')['cash_flow_to_price'].mean()\n",
        "for col, ratio in zip(columns, average_cash_flow_to_price):\n",
        "    print(\"{:.3f}\".format(ratio), end=\"\\t\")\n",
        "print()\n",
        "\n",
        "# Print Panel C: Standardized Unexpected Earnings\n",
        "print(\"\\nPanel C: Standardized Unexpected Earnings\")\n",
        "quarters = ['Most recent quarter', 'Next quarter']  # Assuming data for these two quarters\n",
        "for quarter in quarters:\n",
        "    print(quarter, end=\"\\t\")\n",
        "    # Here assuming the column 'sue' already contains the respective quarter's data\n",
        "    average_earnings = result_data.groupby('decile')['sue'].mean()\n",
        "    for col, earnings in zip(columns, average_earnings):\n",
        "        print(\"{:.3f}\".format(earnings), end=\"\\t\")\n",
        "    print()\n",
        "\n",
        "# Panel D: Abnormal Return Around Earnings Announcements\n",
        "print(\"\\nPanel D: Abnormal Return Around Earnings Announcements\")\n",
        "\n",
        "announcement_periods = [1, 2, 3, 4, 5]  # 1 month before earnings announcement, 1, 2, 3, 4 months after\n",
        "\n",
        "for period in announcement_periods:\n",
        "    col_name = f'abr_{period}'\n",
        "    if period == 1:\n",
        "        print(f\"Most recent announcement 1 month before\", end=\"\\t\")\n",
        "    else:\n",
        "        print(f\"{period-1} announcement(s) after portfolio formation\", end=\"\\t\")\n",
        "\n",
        "    if col_name in result_data.columns:\n",
        "        average_abr = result_data.groupby('decile')[col_name].mean()\n",
        "        for decile, abr in zip(range(1, 11), average_abr):\n",
        "            print(f\"{abr:.3f}\", end=\"\\t\")\n",
        "    else:\n",
        "        print(f\"Warning: Column {col_name} not found in the data!\")\n",
        "    print()\n",
        "\n",
        "# Panel E: Revision in Analyst Forecasts\n",
        "print(\"\\nPanel E: Revision in Analyst Forecasts\")\n",
        "\n",
        "# Calculate \"Average over next 6 months\"\n",
        "result_data.reset_index(drop=True, inplace=True)  # Reset index\n",
        "result_data['avg_revision_next_6_months'] = result_data.groupby('permno')['revision'].rolling(window=6).mean().reset_index(level=0, drop=True).shift(-6)\n",
        "\n",
        "# Calculate \"Average from months 7\"\n",
        "result_data['avg_revision_from_month_7'] = result_data.groupby('permno')['revision'].expanding(min_periods=7).mean().reset_index(level=0, drop=True).shift(-7)\n",
        "\n",
        "forecast_periods = [\"revision\", \"avg_revision_next_6_months\", \"avg_revision_from_month_7\"]\n",
        "forecast_period_names = [\"Most recent revision\", \"Average over next 6 months\", \"Average from months 7\"]\n",
        "\n",
        "for period, period_name in zip(forecast_periods, forecast_period_names):\n",
        "    col_name = period\n",
        "    print(period_name, end=\"\\t\")\n",
        "\n",
        "    if col_name in result_data.columns:\n",
        "        average_revision = result_data.groupby('decile')[col_name].mean()\n",
        "        for decile, revision in zip(range(1, 11), average_revision):\n",
        "            print(f\"{revision:.3f}\", end=\"\\t\")\n",
        "    else:\n",
        "        print(f\"Warning: Column {col_name} not found in the data!\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULmLlC0L1ndp",
        "outputId": "477a4a95-a096-4fb5-ea31-cca274a5ec39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-268bad4ab60c>:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  final_data = pd.read_csv(file_path, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panel A: Returns\n",
            "Return 6 months after portfolio formation\t-0.808\t-2.018\t-2.612\t-0.034\t0.185\t-0.806\t0.773\t-0.683\t0.360\t0.901\t\n",
            "Return 12 months after portfolio formation\t-1.616\t-4.036\t-5.223\t-0.067\t0.371\t-1.612\t1.546\t-1.366\t0.720\t1.802\t\n",
            "Return 24 months after portfolio formation\t-3.232\t-8.073\t-10.447\t-0.135\t0.741\t-3.224\t3.091\t-2.732\t1.440\t3.604\t\n",
            "Return 36 months after portfolio formation\t-4.848\t-12.109\t-15.670\t-0.202\t1.112\t-4.836\t4.637\t-4.099\t2.160\t5.406\t\n",
            "\n",
            "Panel B: Characteristics\n",
            "Book-to-market ratio\t0.389\t3.323\t3.544\t0.015\t0.434\t0.300\t1.724\t0.461\t0.320\t0.630\t\n",
            "Cash flow-to-price ratio\t0.085\t0.203\t-0.022\t-0.025\t0.037\t0.056\t0.345\t0.055\t-0.388\t0.132\t\n",
            "\n",
            "Panel C: Standardized Unexpected Earnings\n",
            "Most recent quarter\t-0.034\t0.022\t-0.008\t0.006\t-0.004\t-0.021\t-0.012\t0.042\t-0.045\t-0.018\t\n",
            "Next quarter\t-0.034\t0.022\t-0.008\t0.006\t-0.004\t-0.021\t-0.012\t0.042\t-0.045\t-0.018\t\n",
            "\n",
            "Panel D: Abnormal Return Around Earnings Announcements\n",
            "Most recent announcement 1 month before\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t0.389\tnan\t0.350\t\n",
            "1 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "2 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "3 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "4 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "\n",
            "Panel E: Revision in Analyst Forecasts\n",
            "Most recent revision\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "Average over next 6 months\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "Average from months 7\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "file_path = 'final_merged_data.csv'\n",
        "final_data = pd.read_csv(file_path, error_bad_lines=False)\n",
        "final_data['date'] = pd.to_datetime(final_data['date'])\n",
        "\n",
        "# Ensure data is sorted by time and permno\n",
        "final_data.sort_values(by=['permno', 'date'], inplace=True)\n",
        "\n",
        "# Calculate future returns for each different time period\n",
        "time_periods = [6, 12, 24, 36]  # 6 months, 1 year, 2 years, 3 years\n",
        "for period in time_periods:\n",
        "    col_name = f'future_{period}_month_return'\n",
        "    final_data[col_name] = final_data.groupby('permno')['ret'].rolling(window=period).sum().shift(-period).reset_index(level=0, drop=True)\n",
        "\n",
        "# Filter data: Only keep rows with necessary return data\n",
        "final_data.dropna(subset=['six_month_return', 'book_to_market', 'cash_flow_to_price'] + [f'future_{period}_month_return' for period in time_periods], inplace=True)\n",
        "\n",
        "# Get unique months\n",
        "unique_dates = final_data['date'].unique()\n",
        "\n",
        "# Initialize result DataFrame\n",
        "result_data = pd.DataFrame()\n",
        "\n",
        "# Function to classify stocks based on selected method\n",
        "def classify_by_choice(monthly_data, choice):\n",
        "    if choice == \"1\":\n",
        "        return monthly_data.sort_values(by='six_month_return', ascending=False)\n",
        "    elif choice == \"2\":\n",
        "        return monthly_data.sort_values(by='sue', ascending=False)\n",
        "    elif choice == \"3\":\n",
        "        return monthly_data.sort_values(by='abr_1', ascending=False)  # Assuming using the most recent month's abnormal return\n",
        "    elif choice == \"4\":\n",
        "        return monthly_data.sort_values(by='revision', ascending=False)\n",
        "\n",
        "# Prompt user for choice of ranking method\n",
        "print(\"Please select a ranking method:\")\n",
        "print(\"1. Six-month return\")\n",
        "print(\"2. Standardized Unexpected Earnings (SUE)\")\n",
        "print(\"3. Abnormal Return before earnings announcement (ABR)\")\n",
        "print(\"4. Analyst forecast revision\")\n",
        "print(\"5. All of the above methods\")\n",
        "choice = input(\"Enter your choice (1/2/3/4/5):\")\n",
        "\n",
        "# Initialize list for result tables\n",
        "result_tables = []\n",
        "\n",
        "# Generate tables for each choice\n",
        "if choice == \"5\":\n",
        "    for ch in [\"1\", \"2\", \"3\", \"4\"]:\n",
        "        result_data = pd.DataFrame()\n",
        "        for date in unique_dates:\n",
        "            monthly_data = final_data[final_data['date'] == date].copy()\n",
        "            if monthly_data.empty:\n",
        "                continue\n",
        "            monthly_data = classify_by_choice(monthly_data, ch)\n",
        "            decile_size = len(monthly_data) // 10\n",
        "            monthly_data['decile'] = (monthly_data.index // decile_size) + 1\n",
        "            monthly_data.loc[monthly_data['decile'] > 10, 'decile'] = 10\n",
        "            result_data = pd.concat([result_data, monthly_data], axis=0)\n",
        "        result_tables.append(result_data)\n",
        "else:\n",
        "    result_data = pd.DataFrame()\n",
        "    for date in unique_dates:\n",
        "        monthly_data = final_data[final_data['date'] == date].copy()\n",
        "        if monthly_data.empty:\n",
        "            continue\n",
        "        monthly_data = classify_by_choice(monthly_data, choice)\n",
        "        decile_size = len(monthly_data) // 10\n",
        "        monthly_data['decile'] = (monthly_data.index // decile_size) + 1\n",
        "        monthly_data.loc[monthly_data['decile'] > 10, 'decile'] = 10\n",
        "        result_data = pd.concat([result_data, monthly_data], axis=0)\n",
        "    result_tables.append(result_data)\n",
        "\n",
        "# Print Panel A and Panel B\n",
        "columns = ['\"1\\n(Low)\"'] + [str(i) for i in range(2, 10)] + ['\"10\\n(High)\"']\n",
        "print(\"Panel A: Returns\")\n",
        "for i, table in enumerate(result_tables):\n",
        "    print(f\"Table {i + 1}\")\n",
        "    for period in time_periods:\n",
        "        col_name = f'future_{period}_month_return'\n",
        "        print(f'Return {period} months after portfolio formation', end=\"\\t\")\n",
        "        average_returns = table.groupby('decile')[col_name].mean()\n",
        "        for col, ret in zip(columns, average_returns):\n",
        "            print(\"{:.3f}\".format(ret), end=\"\\t\")\n",
        "        print()\n",
        "\n",
        "    print(\"\\nPanel B: Characteristics\")\n",
        "\n",
        "    # Calculate and print Book-to-market ratio for each decile\n",
        "    print(\"Book-to-market ratio\", end=\"\\t\")\n",
        "    average_book_to_market = table.groupby('decile')['book_to_market'].mean()\n",
        "    for col, ratio in zip(columns, average_book_to_market):\n",
        "        print(\"{:.3f}\".format(ratio), end=\"\\t\")\n",
        "    print()\n",
        "\n",
        "    # Calculate and print Cash flow-to-price ratio for each decile\n",
        "    print(\"Cash flow-to-price ratio\", end=\"\\t\")\n",
        "    average_cash_flow_to_price = table.groupby('decile')['cash_flow_to_price'].mean()\n",
        "    for col, ratio in zip(columns, average_cash_flow_to_price):\n",
        "        print(\"{:.3f}\".format(ratio), end=\"\\t\")\n",
        "    print()\n",
        "\n",
        "    # Print Panel C: Standardized Unexpected Earnings\n",
        "    print(\"\\nPanel C: Standardized Unexpected Earnings\")\n",
        "    for quarter in quarters:\n",
        "        print(quarter, end=\"\\t\")\n",
        "        average_earnings = table.groupby('decile')['sue'].mean()\n",
        "        for col, earnings in zip(columns, average_earnings):\n",
        "            print(\"{:.3f}\".format(earnings), end=\"\\t\")\n",
        "        print()\n",
        "\n",
        "    # Panel D: Abnormal Return Around Earnings Announcements\n",
        "    print(\"\\nPanel D: Abnormal Return Around Earnings Announcements\")\n",
        "\n",
        "    for period in announcement_periods:\n",
        "        col_name = f'abr_{period}'\n",
        "        if period == 1:\n",
        "            print(f\"Most recent announcement 1 month before\", end=\"\\t\")\n",
        "        else:\n",
        "            print(f\"{period-1} announcement(s) after portfolio formation\", end=\"\\t\")\n",
        "\n",
        "        if col_name in table.columns:\n",
        "            average_abr = table.groupby('decile')[col_name].mean()\n",
        "            for decile, abr in zip(range(1, 11), average_abr):\n",
        "                print(f\"{abr:.3f}\", end=\"\\t\")\n",
        "        else:\n",
        "            print(f\"Warning: Column {col_name} not found in the data!\")\n",
        "        print()\n",
        "\n",
        "    # Panel E: Revision in Analyst Forecasts\n",
        "    print(\"\\nPanel E: Revision in Analyst Forecasts\")\n",
        "\n",
        "    result_table.reset_index(drop=True, inplace=True)\n",
        "    result_table['avg_revision_next_6_months'] = result_table.groupby('permno')['revision'].rolling(window=6).mean().reset_index(level=0, drop=True).shift(-6)\n",
        "    result_table['avg_revision_from_month_7'] = result_table.groupby('permno')['revision'].expanding(min_periods=7).mean().reset_index(level=0, drop=True).shift(-7)\n",
        "\n",
        "    forecast_periods = [\"revision\", \"avg_revision_next_6_months\", \"avg_revision_from_month_7\"]\n",
        "    forecast_period_names = [\"Most recent revision\", \"Average over next 6 months\", \"Average from months 7\"]\n",
        "\n",
        "    for period, period_name in zip(forecast_periods, forecast_period_names):\n",
        "        col_name = period\n",
        "        print(period_name, end=\"\\t\")\n",
        "\n",
        "        if col_name in result_table.columns:\n",
        "            average_revision = result_table.groupby('decile')[col_name].mean()\n",
        "            for decile, revision in zip(range(1, 11), average_revision):\n",
        "                print(f\"{revision:.3f}\", end=\"\\t\")\n",
        "        else:\n",
        "            print(f\"Warning: Column {col_name} not found in the data!\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "XGtmd1UNP84T",
        "outputId": "1fdeca0e-0a9f-4f77-8d7a-b2a6ee469be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-2fe8b2424700>:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  final_data = pd.read_csv(file_path, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "请选择排名方式：\n",
            "1. 六个月收益率\n",
            "2. 标准化意外收益（SUE）\n",
            "3. 财报发布前一个月的异常回报（ABR）\n",
            "4. 分析师预测修订\n",
            "5. 所有上述方式\n",
            "请输入选择（1/2/3/4/5）：5\n",
            "Panel A: Returns\n",
            "Table 1\n",
            "Return 6 months after portfolio formation\t-0.845\t-2.510\t-1.782\t0.152\t-0.504\t0.470\t-0.376\t0.090\t3.004\t0.498\t\n",
            "Return 12 months after portfolio formation\t-1.689\t-5.019\t-3.564\t0.304\t-1.008\t0.939\t-0.753\t0.180\t6.008\t0.996\t\n",
            "Return 24 months after portfolio formation\t-3.378\t-10.038\t-7.128\t0.608\t-2.015\t1.878\t-1.506\t0.360\t12.016\t1.992\t\n",
            "Return 36 months after portfolio formation\t-5.067\t-15.057\t-10.692\t0.912\t-3.023\t2.818\t-2.259\t0.540\t18.025\t2.988\t\n",
            "\n",
            "Panel B: Characteristics\n",
            "Book-to-market ratio\t0.367\t4.283\t2.147\t-0.044\t0.343\t1.518\t0.532\t0.342\t0.427\t0.695\t\n",
            "Cash flow-to-price ratio\t0.078\t0.250\t-0.128\t-0.048\t0.068\t0.312\t0.048\t-0.266\t0.018\t0.143\t\n",
            "\n",
            "Panel C: Standardized Unexpected Earnings\n",
            "Most recent quarter\t-0.026\t0.003\t0.032\t-0.055\t0.003\t-0.016\t0.018\t-0.029\t-0.038\t-0.008\t\n",
            "Next quarter\t-0.026\t0.003\t0.032\t-0.055\t0.003\t-0.016\t0.018\t-0.029\t-0.038\t-0.008\t\n",
            "\n",
            "Panel D: Abnormal Return Around Earnings Announcements\n",
            "Most recent announcement 1 month before\tnan\tnan\tnan\tnan\tnan\tnan\t0.389\tnan\t0.010\t0.162\t\n",
            "1 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "2 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "3 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "4 announcement(s) after portfolio formation\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\t\n",
            "\n",
            "Panel E: Revision in Analyst Forecasts\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2fe8b2424700>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPanel E: Revision in Analyst Forecasts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mresult_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mresult_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_revision_next_6_months'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'permno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mresult_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_revision_from_month_7'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'permno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result_table' is not defined"
          ]
        }
      ]
    }
  ]
}
